{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "814ccff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "from collections import ChainMap\n",
    "import argparse\n",
    "import random\n",
    "import os\n",
    "import datetime\n",
    "import re\n",
    "import hashlib\n",
    "from enum import Enum\n",
    "import librosa\n",
    "import pcen\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torch._six import with_metaclass\n",
    "from torch._C import _ImperativeEngine as ImperativeEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd2edaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_config():\n",
    "    config = {}\n",
    "    # model set\n",
    "    config[\"group_speakers_by_id\"] = True\n",
    "    config[\"input_file\"] = None   # model\\EdgeCRNN-2x.pt\n",
    "    config[\"n_labels\"] = 12\n",
    "    config[\"no_cuda\"] = False\n",
    "\n",
    "    # input shape\n",
    "    config[\"silence_prob\"] = 0.1\n",
    "    config[\"noise_prob\"] = 0.8\n",
    "    config[\"n_dct_filters\"] = 40\n",
    "    config[\"input_length\"] = 16000\n",
    "    config[\"n_mels\"] = 13  # MFCC-》39， log_mel->13 PCEN\n",
    "    config[\"timeshift_ms\"] = 100\n",
    "    config[\"unknown_prob\"] = 0.1\n",
    "    config[\"train_pct\"] = 80\n",
    "    config[\"dev_pct\"] = 10\n",
    "    config[\"test_pct\"] = 10\n",
    "    config[\"wanted_words\"] = [\"zero\", \"one \", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\"]\n",
    "    config[\"data_folder\"] = \"/home/koushik/Documents/code/repos/KWS/data\"\n",
    "    config[\"audio_preprocess_type\"] = \"MFCCs\"\n",
    "    config[\"feature_type\"] = \"log_mel\"  # [\"MFCC\", \"log_mel\", PCEN]\n",
    "\n",
    "    # train parameter\n",
    "    config[\"n_epochs\"] = 1\n",
    "    config[\"add_noise\"] = True\n",
    "    config[\"type\"] = \"train\"  # [train, eval]\n",
    "    config[\"loss\"] = \"focal\"  # [\"CE\", \"focal\"]\n",
    "    config[\"optimizer\"] = \"adam\"  # [\"adam\", \"sgd\"]\n",
    "    config[\"model_type\"] = \"EdgeCRNN\"  # [\"EdgeCRNN\",\"shuffleNet\", \"Tpool2\",\n",
    "    #  \"rnn\", \"mobileNet\", \"mobileNetV3-Small\", \"mobileNetV3-Large\"]\n",
    "    config[\"preprocess_data\"] = 2  # [1, 2]  2 online, 1 offline\n",
    "    config[\"width_mult\"] = 1\n",
    "    config[\"output_file\"] = \"model/EdgeCRNN\"  #\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb493585",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigBuilder(object):\n",
    "    def __init__(self, *default_configs):\n",
    "        self.default_config = ChainMap(*default_configs)\n",
    "\n",
    "    def build_argparse(self):\n",
    "        parser = argparse.ArgumentParser()\n",
    "        for key, value in self.default_config.items():\n",
    "            key = \"--{}\".format(key)\n",
    "            if isinstance(value, tuple):\n",
    "                parser.add_argument(key, default=list(value), nargs=len(value), type=type(value[0]))\n",
    "            elif isinstance(value, list):\n",
    "                parser.add_argument(key, default=value, nargs=\"+\", type=type(value[0]))\n",
    "            elif isinstance(value, bool) and not value:\n",
    "                parser.add_argument(key, action=\"store_true\")\n",
    "            else:\n",
    "                parser.add_argument(key, default=value, type=type(value))\n",
    "        return parser\n",
    "\n",
    "    def config_from_argparse(self, parser=None):\n",
    "        if not parser:\n",
    "            parser = self.build_argparse()\n",
    "        args = vars(parser.parse_known_args()[0])\n",
    "        return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ea22dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frist_conv(inp, oup):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, 1, 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU(inplace=True)  # nn.Relu()\n",
    "    )\n",
    "\n",
    "def conv_1x1_bn(inp, oup):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        # nn.PReLU()\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "def channel_shuffle(x, groups):\n",
    "    batchsize, num_channels, height, width = x.data.size()\n",
    "\n",
    "    channels_per_group = num_channels // groups\n",
    "\n",
    "    # reshape\n",
    "    x = x.view(batchsize, groups, channels_per_group, height, width)\n",
    "\n",
    "    x = torch.transpose(x, 1, 2).contiguous()  # (batchsize, channels_per_group, groups, height, width)\n",
    "\n",
    "    # flatten\n",
    "    x = x.view(batchsize, -1, height, width)  # (batchsize, -1, height, width)\n",
    "\n",
    "    return x\n",
    "\n",
    "def Base_block(oup_inc, stride):\n",
    "\n",
    "    banch = nn.Sequential(\n",
    "        # pw\n",
    "        nn.Conv2d(oup_inc, oup_inc, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(oup_inc),\n",
    "        nn.ReLU(inplace=True),\n",
    "        # dw\n",
    "        nn.Conv2d(oup_inc, oup_inc, 3, stride, 1, groups=oup_inc, bias=False),\n",
    "        nn.BatchNorm2d(oup_inc),\n",
    "        # pw-linear\n",
    "        nn.Conv2d(oup_inc, oup_inc, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(oup_inc),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "    return banch\n",
    "\n",
    "def EdgeCRNN_block(inp, oup_inc, stride):\n",
    "    left_banch = nn.Sequential(\n",
    "        # dw\n",
    "        nn.Conv2d(inp, inp, 3, stride, 1, groups=inp, bias=False),\n",
    "        nn.BatchNorm2d(inp),\n",
    "        # pw-linear\n",
    "        nn.Conv2d(inp, oup_inc, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(oup_inc),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "    right_banch = nn.Sequential(\n",
    "                # pw\n",
    "                nn.Conv2d(inp, oup_inc, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup_inc),\n",
    "                nn.ReLU(inplace=True),\n",
    "                # dw\n",
    "                nn.Conv2d(oup_inc, oup_inc, 3, stride, 1, groups=oup_inc, bias=False),\n",
    "                nn.BatchNorm2d(oup_inc),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(oup_inc, oup_inc, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup_inc),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "    return left_banch, right_banch\n",
    "\n",
    "class EdgeCRNN_Residual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, benchmodel):\n",
    "        super(EdgeCRNN_Residual, self).__init__()\n",
    "        self.benchmodel = benchmodel\n",
    "        self.stride = stride\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        oup_inc = oup // 2\n",
    "\n",
    "        if self.benchmodel == 1:\n",
    "            # assert inp == oup_inc\n",
    "            self.banch2 = Base_block(oup_inc, stride)\n",
    "        else:\n",
    "            self.banch1, self.banch2 = EdgeCRNN_block(inp, oup_inc, stride)\n",
    "\n",
    "    @staticmethod\n",
    "    def _concat(x, out):\n",
    "        # concatenate along channel axis\n",
    "        return torch.cat((x, out), 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if 1 == self.benchmodel:\n",
    "            x1 = torch.chunk(x, 2, 1)[0]\n",
    "            x2 = torch.chunk(x, 2, 1)[1]\n",
    "            out = self._concat(x1, self.banch2(x2))\n",
    "        elif 2 == self.benchmodel:\n",
    "            out = self._concat(self.banch1(x), self.banch2(x))\n",
    "\n",
    "        return channel_shuffle(out, 2)\n",
    "\n",
    "class EdgeCRNN(nn.Module):\n",
    "    def __init__(self, n_class=12, input_size=101, width_mult=1.):\n",
    "        super(EdgeCRNN, self).__init__()\n",
    "\n",
    "        # assert input_size % 32 == 0\n",
    "\n",
    "        self.stage_repeats = [2, 3, 2]\n",
    "        # index 0 is invalid and should never be called.\n",
    "        # only used for indexing convenience.\n",
    "        if width_mult == 0.5:\n",
    "            self.stage_out_channels = [-1, 16, 32, 64, 128, 256]  # *2  *2  16,  32,  64, 128, 256\n",
    "        elif width_mult == 1.0:\n",
    "            self.stage_out_channels = [-1, 24, 72, 144, 288, 512]  # *4.9 *2  24, 72, 144, 288, 512\n",
    "        elif width_mult == 1.5:\n",
    "            self.stage_out_channels = [-1, 24, 116, 232, 464, 1024]  # *7.3 *2\n",
    "        elif width_mult == 2.0:\n",
    "            self.stage_out_channels = [-1, 24, 160, 320, 640, 1024]  # *9.3  *2\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"\"\"groups is not supported for\n",
    "                       1x1 Grouped Convolutions\"\"\")\n",
    "        # building first layer\n",
    "        input_channel = self.stage_out_channels[1]\n",
    "        self.conv1 = frist_conv(1, input_channel)  # 1 dim\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.features = []\n",
    "        # building Stage2-4\n",
    "        for idxstage in range(len(self.stage_repeats)):\n",
    "            numrepeat = self.stage_repeats[idxstage]\n",
    "            output_channel = self.stage_out_channels[idxstage + 2]\n",
    "            for i in range(numrepeat):\n",
    "                if i == 0:\n",
    "                    # inp, oup, stride, benchmodel):\n",
    "                    self.features.append(EdgeCRNN_Residual(input_channel, output_channel, 2, 2))\n",
    "                else:\n",
    "                    self.features.append(EdgeCRNN_Residual(input_channel, output_channel, 1, 1))\n",
    "                input_channel = output_channel\n",
    "        # make it nn.Sequential\n",
    "        self.features = nn.Sequential(*self.features)  # 16层网络\n",
    "        # building last several layers\n",
    "        self.conv_last = conv_1x1_bn(input_channel, self.stage_out_channels[-1])\n",
    "\n",
    "        self.globalpool = nn.Sequential(nn.AvgPool2d((3, 1), stride=(1, 1)))  # rnn->cnn (3,1)->(3, 7)\n",
    "        # first-layer(3,1),other(2,1)； cnn first（3,7），other（2,4）\n",
    "\n",
    "        # add RNN block\n",
    "        self.hidden_size = 64\n",
    "        # self.RNN = nn.RNN(self.stage_out_channels[-1], self.hidden_size, num_layers=1, batch_first=True)\n",
    "        self.RNN = nn.LSTM(self.stage_out_channels[-1], self.hidden_size, num_layers=1, batch_first=True)\n",
    "        # self.RNN = nn.GRU(self.stage_out_channels[-1], self.hidden_size, num_layers=1, batch_first=True)\n",
    "        self.classifier = nn.Sequential(nn.Linear(self.hidden_size, n_class))\n",
    "\n",
    "        # building classifier CNN\n",
    "        # self.classifier = nn.Sequential(nn.Linear(self.stage_out_channels[-1], n_class))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.features(x)\n",
    "        x = self.conv_last(x)\n",
    "        # print(x.shape)\n",
    "        x = self.globalpool(x)  # shape(64,1024,1,4)\n",
    "\n",
    "        # CNN\n",
    "        # x = x.squeeze()\n",
    "        # x = x.view(-1, self.stage_out_channels[-1])\n",
    "\n",
    "        # add RNN block\n",
    "        x = x.squeeze(dim=2).permute(0, 2, 1)  # shape(64,1024,1,4)--> shape(b, w, c)  (64, 7, 1024)\n",
    "        self.RNN.flatten_parameters()\n",
    "        x, _ = self.RNN(x)  # shape(64, 7, 1024)\n",
    "        x = x.permute(0, 2, 1).mean(2)  # shape(1, 64,1024)--> (64,1024, 7)\n",
    "\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a85993ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(config):\n",
    "    seed = int(config[\"seed\"])\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if not config[\"no_cuda\"]:\n",
    "        torch.cuda.manual_seed(seed)\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "245d81a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariableMeta(type):\n",
    "    def __instancecheck__(cls, other):\n",
    "        return isinstance(other, torch.Tensor)\n",
    "\n",
    "class Variable(with_metaclass(VariableMeta, torch._C._LegacyVariableBase)):  # type: ignore[misc]\n",
    "    pass\n",
    "\n",
    "Variable._execution_engine = ImperativeEngine()\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    r\"\"\"\n",
    "        This criterion is a implemenation of Focal Loss, which is proposed in\n",
    "        Focal Loss for Dense Object Detection.\n",
    "\n",
    "            Loss(x, class) = - \\alpha (1-softmax(x)[class])^gamma \\log(softmax(x)[class])\n",
    "\n",
    "        The losses are averaged across observations for each minibatch.\n",
    "        Args:\n",
    "            alpha(1D Tensor, Variable) : the scalar factor for this criterion\n",
    "            gamma(float, double) : gamma > 0; reduces the relative loss for well-classiﬁed examples (p > .5),\n",
    "                                   putting more focus on hard, misclassiﬁed examples\n",
    "            size_average(bool): size_average(bool): By default, the losses are averaged over observations for each minibatch.\n",
    "                                However, if the field size_average is set to False, the losses are\n",
    "                                instead summed for each minibatch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, alpha=torch.Tensor([1]), gamma=2, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "\n",
    "        if isinstance(alpha, Variable):\n",
    "            self.alpha = alpha\n",
    "        else:\n",
    "            self.alpha = Variable(alpha)\n",
    "        self.gamma = gamma\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        N = inputs.size(0)\n",
    "        C = inputs.size(1)\n",
    "        P = F.softmax(inputs, dim=1)\n",
    "\n",
    "        class_mask = inputs.data.new(N, C).fill_(0)\n",
    "        class_mask = Variable(class_mask)\n",
    "        ids = targets.view(-1, 1)  # shape(N, 1)\n",
    "        class_mask.scatter_(1, ids.data, 1.)\n",
    "        # print(class_mask)\n",
    "\n",
    "        if inputs.is_cuda and not self.alpha.is_cuda:\n",
    "            self.alpha = self.alpha.cuda()\n",
    "        # alpha = self.alpha[ids.data.view(-1)]\n",
    "\n",
    "        probs = (P * class_mask).sum(1).view(-1, 1)\n",
    "\n",
    "        log_p = probs.log()\n",
    "        # print('probs size= {}'.format(probs.size()))\n",
    "        # print(probs)\n",
    "\n",
    "        batch_loss = -self.alpha * (torch.pow((1 - probs), self.gamma)) * log_p\n",
    "        # print('-----bacth_loss------')\n",
    "        # print(batch_loss)\n",
    "\n",
    "        if self.size_average:\n",
    "            loss = batch_loss.mean()\n",
    "        else:\n",
    "            loss = batch_loss.sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b0b63f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetType(Enum):\n",
    "    TRAIN = 0\n",
    "    DEV = 1\n",
    "    TEST = 2\n",
    "\n",
    "class SpeechDataset(data.Dataset):\n",
    "    LABEL_SILENCE = \"__silence__\"  # public static variable\n",
    "    LABEL_UNKNOWN = \"__unknown__\"\n",
    "    def __init__(self, data, set_type, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.audio_files = list(data.keys())\n",
    "        self.set_type = set_type\n",
    "        self.audio_labels = list(data.values())\n",
    "        config[\"bg_noise_files\"] = list(filter(lambda x: x.endswith(\"wav\"), config.get(\"bg_noise_files\", [])))\n",
    "        self.bg_noise_audio = [librosa.core.load(file, sr=16000)[0] for file in config[\"bg_noise_files\"]]\n",
    "        self.unknown_prob = config[\"unknown_prob\"]\n",
    "        self.silence_prob = config[\"silence_prob\"]\n",
    "        self.noise_prob = config[\"noise_prob\"]\n",
    "        self.input_length = config[\"input_length\"]\n",
    "        self.timeshift_ms = config[\"timeshift_ms\"]\n",
    "        self._audio_cache = SimpleCache(config[\"cache_size\"])\n",
    "        self._file_cache = SimpleCache(config[\"cache_size\"])\n",
    "        n_unk = len(list(filter(lambda x: x == 1, self.audio_labels)))\n",
    "        self.n_silence = int(self.silence_prob * (len(self.audio_labels) - n_unk))\n",
    "        self.audio_processor = AudioPreprocessor(n_mels=config[\"n_mels\"], n_dct_filters=config[\"n_dct_filters\"], hop_ms=10, config=config)\n",
    "        self.audio_preprocess_type = config[\"audio_preprocess_type\"]\n",
    "        self.n_mels = config[\"n_mels\"]\n",
    "\n",
    "    @staticmethod\n",
    "    def default_config():\n",
    "        config = {}\n",
    "        config[\"group_speakers_by_id\"] = True\n",
    "        config[\"silence_prob\"] = 0.1\n",
    "        config[\"noise_prob\"] = 0.8\n",
    "        config[\"n_dct_filters\"] = 40\n",
    "        config[\"input_length\"] = 16000\n",
    "        config[\"n_mels\"] = 40\n",
    "        config[\"timeshift_ms\"] = 100\n",
    "        config[\"unknown_prob\"] = 0.1\n",
    "        config[\"train_pct\"] = 80\n",
    "        config[\"dev_pct\"] = 10\n",
    "        config[\"test_pct\"] = 10\n",
    "        config[\"wanted_words\"] = [\"command\", \"random\"]\n",
    "        config[\"data_folder\"] = \"data/speech_dataset\"\n",
    "        config[\"audio_preprocess_type\"] = \"MFCCs\"\n",
    "        return config\n",
    "\n",
    "    def collate_fn(self, data):\n",
    "        x = None\n",
    "        y = []\n",
    "        mult = 1\n",
    "        if self.config[\"feature_type\"] == \"log_mel\":\n",
    "            mult = 3\n",
    "        # print(\"collate star:\", time.time())\n",
    "        for audio_data, label in data:   # data and label\n",
    "            if self.audio_preprocess_type == \"MFCCs\":\n",
    "                audio_tensor = torch.from_numpy(self.audio_processor.compute_mfccs(audio_data).reshape(1, self.config[\"n_mels\"]*mult, 101))  # shape（b, h, w）\n",
    "                x = audio_tensor if x is None else torch.cat((x, audio_tensor), 0)\n",
    "            elif self.audio_preprocess_type == \"PCEN\":\n",
    "                audio_tensor = torch.from_numpy(np.expand_dims(audio_data, axis=0))\n",
    "                audio_tensor = self.audio_processor.compute_pcen(audio_tensor)\n",
    "                x = audio_tensor if x is None else torch.cat((x, audio_tensor), 0)\n",
    "            y.append(label)\n",
    "        # print(\"collate end:\", time.time())\n",
    "        return x, torch.tensor(y)\n",
    "\n",
    "    def _timeshift_audio(self, data):\n",
    "        shift = (16000 * self.timeshift_ms) // 1000\n",
    "        shift = random.randint(-shift, shift)\n",
    "        a = -min(0, shift)\n",
    "        b = max(0, shift)\n",
    "        data = np.pad(data, (a, b), \"constant\")\n",
    "        return data[:len(data) - a] if a else data[b:]\n",
    "\n",
    "    def load_audio(self, example, silence=False):\n",
    "        if silence:\n",
    "            example = \"__silence__\"\n",
    "        if random.random() < 0.7:\n",
    "            try:\n",
    "                return self._audio_cache[example]\n",
    "            except KeyError:\n",
    "                pass\n",
    "        in_len = self.input_length\n",
    "        if self.bg_noise_audio:\n",
    "            bg_noise = random.choice(self.bg_noise_audio)\n",
    "            a = random.randint(0, len(bg_noise) - in_len - 1)\n",
    "            bg_noise = bg_noise[a:a + in_len]\n",
    "        else:\n",
    "            bg_noise = np.zeros(in_len)\n",
    "\n",
    "        if silence:\n",
    "            data = np.zeros(in_len)\n",
    "        else:\n",
    "            # augmenter = Compose([\n",
    "            #     AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "            #     # TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
    "            #     PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
    "            #     Shift(min_fraction=-0.5, max_fraction=0.5, p=0.5),\n",
    "            # ])\n",
    "            file_data = self._file_cache.get(example)\n",
    "            data = librosa.core.load(example, sr=16000)[0] if file_data is None else file_data\n",
    "            # data = augmenter(samples=data, sample_rate=16000)\n",
    "            self._file_cache[example] = data\n",
    "        data = np.pad(data, (0, max(0, in_len - len(data))), \"constant\")\n",
    "        if self.set_type == DatasetType.TRAIN:\n",
    "            data = self._timeshift_audio(data)\n",
    "        if self.config[\"add_noise\"]:\n",
    "            if random.random() < self.noise_prob or silence:\n",
    "                a = random.random() * 0.1\n",
    "                data = np.clip(a * bg_noise + data, -1, 1)\n",
    "        # data = np.clip(data, -1, 1)\n",
    "\n",
    "        self._audio_cache[example] = data\n",
    "        return data\n",
    "\n",
    "    @classmethod\n",
    "    def splits(cls, config):\n",
    "        folder = config[\"data_folder\"]  # data/speech_dataset\n",
    "        wanted_words = config[\"wanted_words\"] # ['yes', 'no', 'up', 'down', 'left', 'right', 'on', 'off', 'stop', 'go']\n",
    "        unknown_prob = config[\"unknown_prob\"] # 0.1\n",
    "        train_pct = config[\"train_pct\"]  # 80\n",
    "        dev_pct = config[\"dev_pct\"]  # 10\n",
    "        test_pct = config[\"test_pct\"]  # 10\n",
    "\n",
    "        words = {word: i + 2 for i, word in enumerate(wanted_words)}\n",
    "        # {'yes': 2, 'no': 3, 'up': 4, 'down': 5, 'left': 6, 'right': 7, 'on': 8, 'off': 9, 'stop': 10, 'go': 11}\n",
    "        words.update({cls.LABEL_SILENCE:0, cls.LABEL_UNKNOWN:1})\n",
    "        sets = [{}, {}, {}]\n",
    "        unknowns = [0] * 3\n",
    "        bg_noise_files = []\n",
    "        unknown_files = []\n",
    "\n",
    "        for folder_name in os.listdir(folder):\n",
    "            path_name = os.path.join(folder, folder_name)   # data/speech_dataset/yes\n",
    "            is_bg_noise = False\n",
    "            if os.path.isfile(path_name):\n",
    "                continue\n",
    "            if folder_name in words:\n",
    "                label = words[folder_name]\n",
    "            elif folder_name == \"_background_noise_\":\n",
    "                is_bg_noise = True\n",
    "            else:\n",
    "                label = words[cls.LABEL_UNKNOWN]\n",
    "\n",
    "            for filename in os.listdir(path_name):\n",
    "                wav_name = os.path.join(path_name, filename)  # data/speech_dataset/down/00b01445_nohash_1.wav\n",
    "                if is_bg_noise and os.path.isfile(wav_name):\n",
    "                    bg_noise_files.append(wav_name)\n",
    "                    continue\n",
    "                elif label == words[cls.LABEL_UNKNOWN]:  # here the one\\four folder is the UNKNOWN\n",
    "                    unknown_files.append(wav_name)\n",
    "                    continue\n",
    "                if config[\"group_speakers_by_id\"]:\n",
    "                    hashname = re.sub(r\"_nohash_.*$\", \"\", filename)\n",
    "                max_no_wavs = 2**27 - 1\n",
    "                bucket = int(hashlib.sha1(hashname.encode()).hexdigest(), 16)\n",
    "                # hash values  hexdigest() return 16 jinzhi\n",
    "                bucket = (bucket % (max_no_wavs + 1)) * (100. / max_no_wavs)\n",
    "                if bucket < dev_pct:\n",
    "                    tag = DatasetType.DEV   # TRAIN = 0, DEV = 1, TEST = 2\n",
    "                elif bucket < test_pct + dev_pct:  # dev_pct = 10, test_pct = 10, train_pct = 80\n",
    "                    tag = DatasetType.TEST\n",
    "                else:\n",
    "                    tag = DatasetType.TRAIN\n",
    "                if config[\"type\"] == \"eval\":\n",
    "                    sets[2][wav_name] = label\n",
    "                elif config[\"type\"] == \"train\":\n",
    "                    sets[tag.value][wav_name] = label\n",
    "                #  sets = [\n",
    "                # train  {'00b01445_nohash_1': 1, },  length = 16696\n",
    "                # dev    {'00b01443_nohash_1': 2, },  length = 2316\n",
    "                # test   {'00b01441_nohash_1': 3, }   length = 2311\n",
    "                #  ]\n",
    "\n",
    "        for tag in range(len(sets)):\n",
    "            unknowns[tag] = int(unknown_prob * len(sets[tag]))  # train length, validation, test\n",
    "        random.shuffle(unknown_files)\n",
    "        a = 0\n",
    "        for i, dataset in enumerate(sets):\n",
    "            b = a + unknowns[i]\n",
    "            unk_dict = {u: words[cls.LABEL_UNKNOWN] for u in unknown_files[a:b]}\n",
    "            dataset.update(unk_dict)\n",
    "            a = b\n",
    "            # unk_dict = {\n",
    "            #   0:len(train_dataset)-1,\n",
    "            #   len(train_dataset): len(train+dev_dataset)-1\n",
    "            #   len(train+dev):len(train+dev+test)-1\n",
    "            # }\n",
    "        train_cfg = ChainMap(dict(bg_noise_files=bg_noise_files), config)\n",
    "        test_cfg = ChainMap(dict(bg_noise_files=bg_noise_files, noise_prob=0), config)\n",
    "        # print(test_cfg)\n",
    "        datasets = (cls(sets[0], DatasetType.TRAIN, train_cfg), cls(sets[1], DatasetType.DEV, test_cfg),\n",
    "                    cls(sets[2], DatasetType.TEST, config))\n",
    "        return datasets\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index >= len(self.audio_labels):\n",
    "            return self.load_audio(None, silence=True), 0\n",
    "        return self.load_audio(self.audio_files[index]), self.audio_labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # return len(self.audio_labels) + self.n_silence\n",
    "        return len(self.audio_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d27832ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioPreprocessor(object):\n",
    "    def __init__(self, sr=16000, n_dct_filters=40,  n_mels=40, f_max=4000, f_min=20, n_fft=480, hop_ms=10, config=None):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.n_mels = n_mels  # 40\n",
    "        self.sr = sr\n",
    "        self.f_max = f_max if f_max is not None else sr // 2  # 4000\n",
    "        self.f_min = f_min  # 20\n",
    "        self.n_fft = n_fft  # duan shi fu li ye 480\n",
    "        self.hop_length = sr // 1000 * hop_ms\n",
    "        self.pcen_transform = pcen.StreamingPCENTransform(n_mels=n_mels, n_fft=n_fft, hop_length=self.hop_length, trainable=True)\n",
    "\n",
    "    def compute_mfccs(self, data):\n",
    "        mfcc = librosa.feature.mfcc(\n",
    "            data,\n",
    "            sr=self.sr,\n",
    "            n_mfcc=self.n_mels,\n",
    "            hop_length=self.hop_length\n",
    "        )\n",
    "        mfcc = np.array(mfcc, order=\"F\").astype(np.float32)\n",
    "\n",
    "        if self.config[\"feature_type\"] == \"log_mel\":\n",
    "            mel_spec = librosa.feature.melspectrogram(\n",
    "                data,\n",
    "                sr=self.sr,  # 16000\n",
    "                n_mels=self.n_mels,  # 40\n",
    "                hop_length=self.hop_length,  # 160\n",
    "                n_fft=self.n_fft,  # 480\n",
    "                fmin=self.f_min,  # 20\n",
    "                fmax=self.f_max  # 4000\n",
    "            )\n",
    "            # data[data > 0] = np.log(data[data > 0])\n",
    "            # data = [np.matmul(self.dct_filters, x) for x in np.split(data, data.shape[1], axis=1)]\n",
    "            mel_spec = np.array(mel_spec, order=\"F\").astype(np.float32)\n",
    "\n",
    "            log_mel = librosa.power_to_db(mel_spec)\n",
    "            delta = librosa.feature.delta(mfcc)\n",
    "            delta_delta = librosa.feature.delta(delta)\n",
    "            data = np.vstack([log_mel, delta, delta_delta])  # (120, 101)\n",
    "            return data  # shape(120, 101, 1)\n",
    "        elif self.config[\"feature_type\"] == \"MFCC\":\n",
    "            # print(mfcc.shape)\n",
    "            return mfcc  # data shape(40，101)\n",
    "        elif self.config[\"feature_type\"] == \"PCEN\":\n",
    "            spec = librosa.feature.melspectrogram(data, self.sr, power=1, n_mels=self.n_mels, hop_length=self.hop_length, n_fft=self.n_fft)\n",
    "            pcen = librosa.pcen(spec, self.sr)  # (40,101)\n",
    "            pcen = np.array(pcen, order=\"F\").astype(np.float32)\n",
    "            return pcen\n",
    "\n",
    "    def compute_pcen(self, data):\n",
    "        data = self.pcen_transform(data)\n",
    "        self.pcen_transform.reset()\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5c97ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCache(dict):\n",
    "    def __init__(self, limit):\n",
    "        super().__init__()\n",
    "        self.limit = limit\n",
    "        self.n_keys = 0\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        if key in self.keys():\n",
    "            super().__setitem__(key, value)\n",
    "        elif self.n_keys < self.limit:\n",
    "            self.n_keys += 1\n",
    "            super().__setitem__(key, value)\n",
    "        return value\n",
    "    \n",
    "def print_eval(name, scores, labels, loss, step=0, interval=50, file=None, model_type=None, end=\"\\n\"):\n",
    "    batch_size = labels.size(0)\n",
    "    # print(batch_size, scores.shape)\n",
    "    accuracy = (torch.max(scores, 1)[1].view(batch_size).data == labels.data).float().sum() / batch_size\n",
    "    if model_type == \"eval\":\n",
    "        print(\"the predicted value:\", torch.max(scores, 1)[1].numpy() - 2 )\n",
    "        print(\"the  labels   value:\", labels.numpy() - 2)\n",
    "    if step % interval == 0:\n",
    "        print_result = \"{} accuracy: {:>5}, loss: {:<25}\".format(name, accuracy, loss)\n",
    "        if file:\n",
    "            file.write(print_result+end)\n",
    "        print(print_result)\n",
    "    return accuracy.item()\n",
    "\n",
    "def train(config):\n",
    "    output_dir = os.path.dirname(os.path.abspath(config[\"output_file\"]))\n",
    "    train_path = \"{}-{}-train.txt\".format(config[\"output_file\"], datetime.datetime.now().strftime(\"%m-%d %H.%M.%S\"))\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    model = config[\"model\"]\n",
    "    if config[\"input_file\"]:\n",
    "        if not config[\"no_cuda\"]:\n",
    "            parameters = torch.load(config[\"input_file\"])\n",
    "        else:\n",
    "            parameters = torch.load(config[\"input_file\"], map_location='cpu')\n",
    "        model.load_state_dict(parameters)\n",
    "    if not config[\"no_cuda\"]:\n",
    "        print(config[\"gpu_no\"])\n",
    "        # torch.cuda.set_device(config[\"gpu_no\"])\n",
    "        model.cuda()\n",
    "    if config[\"optimizer\"] == \"sgd\":\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=config[\"lr\"][0], nesterov=config[\"use_nesterov\"], weight_decay=config[\"weight_decay\"], momentum=config[\"momentum\"])\n",
    "    if config[\"optimizer\"] == \"adam\":\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"][0])\n",
    "    if config[\"loss\"] == \"CE\":\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    if config[\"loss\"] == \"focal\":\n",
    "        criterion = FocalLoss()\n",
    "    schedule_steps = config[\"schedule\"]\n",
    "    schedule_steps.append(np.inf)\n",
    "    sched_idx = 0\n",
    "    max_acc = 0\n",
    "    # model = model.float()\n",
    "\n",
    "    train_set, dev_set, test_set = SpeechDataset.splits(config)\n",
    "    train_loader = data.DataLoader(\n",
    "        train_set,\n",
    "        batch_size=config[\"batch_size\"],  # 64\n",
    "        shuffle=True, drop_last=True,\n",
    "        collate_fn=train_set.collate_fn,\n",
    "        num_workers=4\n",
    "    )\n",
    "    dev_loader = data.DataLoader(\n",
    "        dev_set,\n",
    "        batch_size=min(len(dev_set), 16),\n",
    "        shuffle=True,\n",
    "        collate_fn=dev_set.collate_fn,\n",
    "        num_workers=4\n",
    "    )\n",
    "    test_loader = data.DataLoader(\n",
    "        test_set,\n",
    "        batch_size=min(len(test_set), 16),\n",
    "        shuffle=True,\n",
    "        collate_fn=test_set.collate_fn,\n",
    "        num_workers=4\n",
    "    )\n",
    "    step_no = 0\n",
    "\n",
    "    train_file = open(train_path, \"a\")\n",
    "    train_file.write(config[\"output_file\"])\n",
    "    for epoch_idx in range(config[\"n_epochs\"]):\n",
    "        train_accs = []\n",
    "        print(\"epoch {} start time：{}\".format(epoch_idx, datetime.datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")))\n",
    "        for batch_idx, (model_in, labels) in enumerate(train_loader):  # 花费5秒-64, 7秒-128\n",
    "            # print(\"for star:\", time.time())\n",
    "            model.train()  # switch model to train model\n",
    "            optimizer.zero_grad()\n",
    "            if not config[\"no_cuda\"]:\n",
    "                model = model.cuda()\n",
    "                model_in = model_in.cuda()\n",
    "                labels = labels.cuda()\n",
    "            model_in = Variable(model_in, requires_grad=True)\n",
    "            model_in = torch.unsqueeze(model_in, 1)\n",
    "            scores = model(model_in)\n",
    "            labels = Variable(labels, requires_grad=False).long()\n",
    "            loss = criterion(scores, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            step_no += 1\n",
    "            # print(\"for end:\", time.time())\n",
    "            train_accs.append(print_eval(\"[{}] train Epoch:{} step #{}\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\"), epoch_idx, step_no),\n",
    "                                         scores, labels, loss, step_no, file=train_file))\n",
    "\n",
    "        # LR setting, 50 epoch\n",
    "        if (epoch_idx + 1) % 50 == 0:\n",
    "            lr_intel = config[\"lr\"][0] - (epoch_idx + 1) / config[\"n_epochs\"] * (config[\"lr\"][0] - config[\"lr\"][1])\n",
    "            print(\"changing learning rate to {}\".format(lr_intel))\n",
    "            train_file.write(\"changing learning rate to {}\".format(lr_intel))\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr_intel)\n",
    "\n",
    "        print_log = \"[{}] train Epoch:{} Accuracy：{}\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\"), epoch_idx, np.mean(train_accs))\n",
    "        print(print_log)\n",
    "        train_file.write(print_log)\n",
    "        print(\"epoch {} end  time：{}\".format(epoch_idx, datetime.datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")))\n",
    "        # 测试阶段\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            accs = []\n",
    "            index = 0\n",
    "            total_score = torch.Tensor()\n",
    "            total_label = torch.Tensor()\n",
    "            for model_in, labels in dev_loader:\n",
    "                model_in = Variable(model_in, requires_grad=False)\n",
    "                model_in = torch.unsqueeze(model_in, 1)\n",
    "                if not config[\"no_cuda\"]:\n",
    "                    model_in = model_in.cuda()\n",
    "                    labels = labels.cuda()\n",
    "                scores = model(model_in)\n",
    "                labels = Variable(labels, requires_grad=False).long()\n",
    "                if len(total_label):\n",
    "                    total_label = torch.cat((total_label, labels))\n",
    "                    total_score = torch.cat((total_score, scores))\n",
    "                else:\n",
    "                    total_label = labels\n",
    "                    total_score = scores\n",
    "\n",
    "                loss = criterion(scores, labels)\n",
    "                index = index + 1\n",
    "                accs.append(print_eval(\"[{}] dev Epoch:{} \".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\"), epoch_idx),\n",
    "                                       scores, labels, loss, index, file=train_file, interval=30))\n",
    "\n",
    "            if not config[\"no_cuda\"]:\n",
    "                total_score = total_score.cpu()\n",
    "                total_label = total_label.cpu()\n",
    "            avg_acc = np.mean(accs)\n",
    "            print(\"final dev accuracy: {}\".format(avg_acc))\n",
    "            train_file.write(\"[{}] Epochs {} final dev accuracy: {}\\n\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\"), epoch_idx, avg_acc))\n",
    "            if avg_acc > max_acc:\n",
    "                print(\"saving best model...\")\n",
    "                train_file.write(\"the best accuracy:{}, saving best model...\\n\".format(avg_acc))\n",
    "                max_acc = avg_acc\n",
    "                if max_acc > 0.90:\n",
    "                    torch.save(model.state_dict(), config[\"output_file\"]+\"-{:.5f}.pt\".format(avg_acc))\n",
    "                    # 计算ROC曲线\n",
    "                    y_one_hot = label_binarize(total_label, np.arange(config[\"n_labels\"]))\n",
    "                    fpr, tpr, thresholds = metrics.roc_curve(y_one_hot.ravel(), total_score.detach().numpy().ravel())\n",
    "                    np.savetxt(config[\"output_file\"] + \"-{:.4f}-{}.csv\".format(avg_acc, epoch_idx), [fpr, tpr],\n",
    "                               delimiter=',', header=\"FPR,TPR\")\n",
    "                    config[\"input_file\"] = config[\"output_file\"]+\"-{:.5f}.pt\".format(avg_acc)  # input model\n",
    "\n",
    "        evaluate(config, model, test_loader)\n",
    "\n",
    "    train_file.close()\n",
    "\n",
    "    # evaluate(config, model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a42d2d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(config, model=None, test_loader=None):\n",
    "    # config[\"feature_type\"] = \"log_mel\"\n",
    "    if not test_loader:\n",
    "        _, _, test_set = dataset.SpeechDataset.splits(config)\n",
    "        test_loader = data.DataLoader(\n",
    "            test_set,\n",
    "            batch_size=len(test_set),\n",
    "            collate_fn=test_set.collate_fn)\n",
    "\n",
    "    if model == None:\n",
    "        model = config[\"model\"]\n",
    "        if config[\"input_file\"]:\n",
    "            if not config[\"no_cuda\"]:\n",
    "                parameters = torch.load(config[\"input_file\"])\n",
    "            else:\n",
    "                parameters = torch.load(config[\"input_file\"], map_location='cpu')\n",
    "            model.load_state_dict(parameters)\n",
    "        if not config[\"no_cuda\"]:\n",
    "            torch.cuda.set_device(config[\"gpu_no\"])\n",
    "            model.cuda()\n",
    "    model.eval()\n",
    "    results = []\n",
    "    total = 0\n",
    "    for model_in, labels in test_loader:\n",
    "        model_in = Variable(model_in, requires_grad=False)\n",
    "        model_in = torch.unsqueeze(model_in, 1)\n",
    "        if not config[\"no_cuda\"]:\n",
    "            model_in = model_in.cuda()\n",
    "            labels = labels.cuda()\n",
    "        scores = model(model_in)\n",
    "        labels = Variable(labels, requires_grad=False)\n",
    "        # loss = criterion(scores, labels)\n",
    "        total += model_in.size(0)\n",
    "        results.append(print_eval(\"test\", scores, labels, 0, total, model_type=config[\"type\"]) * model_in.size(0))\n",
    "    print(\"final test accuracy: {}\".format(sum(results) / total))\n",
    "    return sum(results) / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d40ea63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    global_config = dict(lr=[0.001, 0.0001], schedule=[np.inf], batch_size=64, dev_every=1, seed=0,\n",
    "                         model=None, use_nesterov=False, gpu_no=0, cache_size=32768, momentum=0.9, weight_decay=0.00001)\n",
    "    builder = ConfigBuilder(default_config(), global_config)\n",
    "    parser = builder.build_argparse()\n",
    "    # parser.add_argument(\"--no_cuda\", type=str2bool, nargs='?', const=True)\n",
    "\n",
    "    config = builder.config_from_argparse(parser)\n",
    "\n",
    "    model = EdgeCRNN(width_mult=config[\"width_mult\"])\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    \n",
    "    config[\"model\"] = model\n",
    "    set_seed(config)\n",
    "    if config[\"type\"] == \"train\":\n",
    "        train(config)\n",
    "    elif config[\"type\"] == \"eval\":\n",
    "        evaluate(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6954d1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "epoch 0 start time：2021-10-31 13.47.34\n",
      "[2021-10-31 13.48.24] train Epoch:0 step #50 accuracy: 0.234375, loss: 1.5652639865875244       \n",
      "[2021-10-31 13.49.09] train Epoch:0 step #100 accuracy: 0.671875, loss: 0.6917768716812134       \n",
      "[2021-10-31 13.50.00] train Epoch:0 step #150 accuracy: 0.78125, loss: 0.41581717133522034      \n",
      "[2021-10-31 13.50.46] train Epoch:0 step #200 accuracy: 0.8125, loss: 0.3848932981491089       \n",
      "[2021-10-31 13.51.37] train Epoch:0 step #250 accuracy:  0.75, loss: 0.41717398166656494      \n",
      "[2021-10-31 13.52.23] train Epoch:0 step #300 accuracy: 0.765625, loss: 0.3950932025909424       \n",
      "[2021-10-31 13.53.13] train Epoch:0 step #350 accuracy: 0.921875, loss: 0.21312862634658813      \n",
      "[2021-10-31 13.53.59] train Epoch:0 step #400 accuracy: 0.828125, loss: 0.2480033040046692       \n",
      "[2021-10-31 13.54.49] train Epoch:0 step #450 accuracy: 0.859375, loss: 0.20732825994491577      \n",
      "[2021-10-31 13.55.16] train Epoch:0 Accuracy：0.7328157484407485\n",
      "epoch 0 end  time：2021-10-31 13.55.16\n",
      "[2021-10-31 13.55.24] dev Epoch:0  accuracy: 0.8125, loss: 0.24410095810890198      \n",
      "[2021-10-31 13.55.31] dev Epoch:0  accuracy:  0.75, loss: 0.5229179859161377       \n",
      "[2021-10-31 13.55.39] dev Epoch:0  accuracy:  0.75, loss: 0.46207940578460693      \n",
      "[2021-10-31 13.55.46] dev Epoch:0  accuracy: 0.9375, loss: 0.18851609528064728      \n",
      "[2021-10-31 13.55.53] dev Epoch:0  accuracy:   1.0, loss: 0.02011791430413723      \n",
      "[2021-10-31 13.56.01] dev Epoch:0  accuracy: 0.8125, loss: 0.3628663122653961       \n",
      "[2021-10-31 13.56.08] dev Epoch:0  accuracy:   1.0, loss: 0.0866062343120575       \n",
      "final dev accuracy: 0.88920704856318\n",
      "saving best model...\n",
      "test accuracy: 0.875, loss: 0                        \n",
      "test accuracy:   1.0, loss: 0                        \n",
      "test accuracy: 0.9375, loss: 0                        \n",
      "test accuracy: 0.9375, loss: 0                        \n",
      "test accuracy: 0.875, loss: 0                        \n",
      "test accuracy: 0.875, loss: 0                        \n",
      "test accuracy: 0.875, loss: 0                        \n",
      "test accuracy: 0.6875, loss: 0                        \n",
      "test accuracy: 0.9375, loss: 0                        \n",
      "test accuracy: 0.6875, loss: 0                        \n",
      "final test accuracy: 0.8759195685328193\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
